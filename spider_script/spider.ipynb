{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json, re\n",
    "from tqdm import tqdm\n",
    "from pkg import claude,config,embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ijh/Desktop/Code/sql-agent/pkg/embedding.py:121: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "vs = embedding.load_vector_store(\"./spider/keyword_store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./spider/example.json') as f:\n",
    "    examples_train = json.load(f)\n",
    "    f.close()\n",
    "    \"\"\"\n",
    "    {\n",
    "        \"original_question\":{\n",
    "            \"origitnal_sql\" = original_sql\n",
    "        }\n",
    "    }\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    dbs[$db_id]\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./spider/test_spider.json') as f:\n",
    "    dbs = json.load(f)\n",
    "    f.close()\n",
    "\"\"\"\n",
    "    dbs[$db_id]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    test[idx]['query']\\n    test[idx]['question']\\n    test[idx]['db_id']\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./spider/spider_data/test.json') as f:\n",
    "    test = json.load(f)\n",
    "    f.close()\n",
    "\"\"\"\n",
    "    test[idx]['query']\n",
    "    test[idx]['question']\n",
    "    test[idx]['db_id']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Tables for Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tables = pd.read_json('./spider/spider_data/test_tables.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_masking = {}\n",
    "for db_idx in range(len(test_tables)):\n",
    "    db = test_tables.loc[db_idx]\n",
    "    db['db_id']\n",
    "    # Masking Keyword : Table Name, Column Name\n",
    "    masking_keyword = []\n",
    "    \n",
    "    for tab in db.table_names:\n",
    "        masking_keyword.append(tab)\n",
    "    for col in range(1,len(db.column_names)):\n",
    "        masking_keyword.append(db.column_names[col][1])\n",
    "    db_name = re.sub(r'\\d+', '', db['db_id'])\n",
    "    db_name = re.sub(r'[^a-zA-Z\\'\\-\\s]', '', db_name)\n",
    "    masking_keyword.append(db_name)\n",
    "    db_masking[db.db_id] = masking_keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = config.get_API_keys('./test.key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/282 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "mask_token = \"[MASK]\"\n",
    "generator = claude.SQLQueryGenerator(api_key)\n",
    "count = 5\n",
    "for idx in tqdm(range(1865,len(test))):\n",
    "    if count == 0: break\n",
    "    t = test[idx]\n",
    "    \n",
    "    db_name = t['db_id']\n",
    "    question = t['question']\n",
    "    answer = t['query']\n",
    "    schema = dbs[t['db_id']]['tables']\n",
    "    foreign_keys = dbs[t['db_id']]['foreign_keys']    \n",
    "    masked_question = t['question']\n",
    "    examples = []\n",
    "    \n",
    "    for keyword in db_masking[db_name]:\n",
    "        patterns = [rf'\\b{re.escape(keyword)}\\b',rf'\\b{re.escape(keyword)}s?\\b']\n",
    "        for pattern in patterns:\n",
    "            masked_question = re.sub(pattern, mask_token, masked_question) \n",
    "    \n",
    "    similar_questions = embedding.search_keywords(vs, masked_question, k =3)\n",
    "    for similar_question, _ in similar_questions:\n",
    "        examples.append(\n",
    "            {\n",
    "            \"question\": similar_question.page_content,\n",
    "            \"query\":examples_train[similar_question.page_content]\n",
    "            }\n",
    "            )\n",
    "        \n",
    "    result = generator.generate_test_query(question=question, tables=schema, examples=examples, foreign_keys=foreign_keys)\n",
    "    break\n",
    "    res.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'db_id': 'planet_1',\n",
       " 'query': 'SELECT T1.Level FROM Has_Clearance AS T1 JOIN Employee AS T2 ON T1.Employee = T2.EmployeeID WHERE T2.position  =  \"Physician\";',\n",
       " 'query_toks': ['SELECT',\n",
       "  'T1.Level',\n",
       "  'FROM',\n",
       "  'Has_Clearance',\n",
       "  'AS',\n",
       "  'T1',\n",
       "  'JOIN',\n",
       "  'Employee',\n",
       "  'AS',\n",
       "  'T2',\n",
       "  'ON',\n",
       "  'T1.Employee',\n",
       "  '=',\n",
       "  'T2.EmployeeID',\n",
       "  'WHERE',\n",
       "  'T2.position',\n",
       "  '=',\n",
       "  '``',\n",
       "  'Physician',\n",
       "  \"''\",\n",
       "  ';'],\n",
       " 'query_toks_no_value': ['select',\n",
       "  't1',\n",
       "  '.',\n",
       "  'level',\n",
       "  'from',\n",
       "  'has_clearance',\n",
       "  'as',\n",
       "  't1',\n",
       "  'join',\n",
       "  'employee',\n",
       "  'as',\n",
       "  't2',\n",
       "  'on',\n",
       "  't1',\n",
       "  '.',\n",
       "  'employee',\n",
       "  '=',\n",
       "  't2',\n",
       "  '.',\n",
       "  'employeeid',\n",
       "  'where',\n",
       "  't2',\n",
       "  '.',\n",
       "  'position',\n",
       "  '=',\n",
       "  'value'],\n",
       " 'question': 'What level is Physician?',\n",
       " 'question_toks': ['What', 'level', 'is', 'Physician', '?'],\n",
       " 'sql': {'from': {'table_units': [['table_unit', 3], ['table_unit', 0]],\n",
       "   'conds': [[False, 2, [0, [0, 13, False], None], [0, 1, False], None]]},\n",
       "  'select': [False, [[0, [0, [0, 15, False], None]]]],\n",
       "  'where': [[False, 2, [0, [0, 3, False], None], '\"Physician\"', None]],\n",
       "  'groupBy': [],\n",
       "  'having': [],\n",
       "  'orderBy': [],\n",
       "  'limit': None,\n",
       "  'intersect': None,\n",
       "  'union': None,\n",
       "  'except': None}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1865]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(result.query.replace('\\n',' ').replace(';',' ').split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = []\n",
    "for r in res:\n",
    "    r1.append(' '.join(r.query.replace('\\n',' ').replace(';',' ').split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test.txt','w') as f:\n",
    "    f.write('\\n'.join(r1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
